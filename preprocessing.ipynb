{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook does the preprocessing for the dataset.\n",
    "\n",
    "1. The bounding boxes and labels are extracted from the annotation files\n",
    "2. The image, bounding box and label are grouped and accumulated in a list\n",
    "3. For training, a train-validation split of 80/20 is done by shuffling the extracted training data and splitting\n",
    "4. These split data is saved into a CSV file for a `CSVGenerator` in the training section to consume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_box(path):\n",
    "    \"\"\"extract_box\n",
    "    Extract annotation box positions for each labels from VIVA hand dataset.\n",
    "    output is a list of tuples.\n",
    "\n",
    "    :param path: text file path\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path) as temp:\n",
    "        output = []\n",
    "\n",
    "        for i, line in enumerate(temp):\n",
    "\n",
    "            if i != 0 and line:\n",
    "                label, x_1, y_1, x_off, y_off, *_ = line.split()\n",
    "                pt_1 = (int(x_1), int(y_1))\n",
    "                pt_2 = (pt_1[0] + int(x_off), (pt_1[1] + int(y_off)))\n",
    "                output.append((label, pt_1, pt_2))\n",
    "\n",
    "    return output\n",
    "\n",
    "def create_csv(image_dir, annotation_dir, csv_out_path, val_out_path=None, val_split=None):\n",
    "    image_paths = sorted(glob.glob(image_dir + '*'))\n",
    "    annotations_paths = sorted(glob.glob(annotation_dir + '*'))\n",
    "\n",
    "    # each image can have up to 4 hand bboxes\n",
    "    rows = []\n",
    "    for image_path, annotations_path in zip(image_paths, annotations_paths):\n",
    "            annotations = extract_box(annotations_path)\n",
    "            for annotation in annotations:\n",
    "                # annotation [label, (x1, y1), (x2, y2)]\n",
    "                # save as image,x1,y2,x2,y2,label\n",
    "                rows.append([image_path,\n",
    "                             annotation[1][0], annotation[1][1],\n",
    "                             annotation[2][0], annotation[2][1],\n",
    "                             annotation[0]])\n",
    "    if val_split:\n",
    "        # shuffle and split\n",
    "        np.random.shuffle(rows)\n",
    "        val_size = int(len(rows) * val_split)\n",
    "        val_rows = rows[:val_size]\n",
    "        with open('./data/validation.csv' if val_out_path is None else val_out_path, 'w') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            for row in val_rows:\n",
    "                writer.writerow(row)\n",
    "        rows = rows[val_size:]\n",
    "\n",
    "    with open(csv_out_path, 'w') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            for row in rows:\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the root directory where the training data is extracted\n",
    "data_dir = '/media/appsyoon/New Volume/Machine Learning/data/'\n",
    "# training data path\n",
    "train_dir = data_dir + 'detectiondata/train/'\n",
    "train_image_dir = train_dir + 'pos/'\n",
    "train_annotation_dir = train_dir + 'posGt/'\n",
    "\n",
    "out_path = './data/train.csv'\n",
    "\n",
    "create_csv(train_image_dir, train_annotation_dir, out_path, val_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the test data images are in the same root dir as training\n",
    "test_image_dir = data_dir + 'detectiondata/test/pos/'\n",
    "# but the annotations are downloaded separately and extracted into data_dir/evaluation/\n",
    "test_annotation_dir = data_dir + 'evaluation/annotations/'\n",
    "\n",
    "test_out_path = './data/test.csv'\n",
    "\n",
    "create_csv(test_image_dir, test_annotation_dir, test_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
