{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook does the preprocessing for the dataset.\n",
    "\n",
    "1. The bounding boxes and labels are extracted from the annotation files\n",
    "2. The image, bounding box and label are grouped and accumulated in a list\n",
    "3. For training, a train-validation split of 80/20 is done by shuffling the extracted training data and splitting\n",
    "4. These split data is saved into a CSV file for a `CSVGenerator` in the training section to consume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_box(path):\n",
    "    \"\"\"extract_box\n",
    "    Extract annotation box positions for each labels from VIVA hand dataset.\n",
    "    output is a list of tuples.\n",
    "\n",
    "    :param path: text file path\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path) as temp:\n",
    "        output = []\n",
    "\n",
    "        for i, line in enumerate(temp):\n",
    "\n",
    "            if i != 0 and line:\n",
    "                label, x_1, y_1, x_off, y_off, *_ = line.split()\n",
    "                pt_1 = (int(x_1), int(y_1))\n",
    "                pt_2 = (pt_1[0] + int(x_off), (pt_1[1] + int(y_off)))\n",
    "                output.append((label, pt_1, pt_2))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(image_dir, annotation_dir, csv_out_path, val_out_path=None, val_split=None):\n",
    "    image_paths = sorted(glob.glob(image_dir + '*'))\n",
    "    annotations_paths = sorted(glob.glob(annotation_dir + '*'))\n",
    "\n",
    "    # each image can have up to 4 hand bboxes\n",
    "    rows = []\n",
    "    for image_path, annotations_path in zip(image_paths, annotations_paths):\n",
    "            annotations = extract_box(annotations_path)\n",
    "            for annotation in annotations:\n",
    "                # annotation [label, (x1, y1), (x2, y2)]\n",
    "                # save as image,x1,y2,x2,y2,label\n",
    "                rows.append([image_path,\n",
    "                             annotation[1][0], annotation[1][1],\n",
    "                             annotation[2][0], annotation[2][1],\n",
    "                             annotation[0]])\n",
    "    if val_split:\n",
    "        # shuffle and split\n",
    "        np.random.shuffle(rows)\n",
    "        val_size = int(len(rows) * val_split)\n",
    "        val_rows = rows[:val_size]\n",
    "        with open('./data/validation.csv' if val_out_path is None else val_out_path, 'w') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            for row in val_rows:\n",
    "                writer.writerow(row)\n",
    "        rows = rows[val_size:]\n",
    "\n",
    "    with open(csv_out_path, 'w') as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            for row in rows:\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the root directory where the training data is extracted\n",
    "data_dir = '/media/appsyoon/New Volume/Machine Learning/data/'\n",
    "# training data path\n",
    "train_dir = data_dir + 'detectiondata/train/'\n",
    "train_image_dir = train_dir + 'pos/'\n",
    "train_annotation_dir = train_dir + 'posGt/'\n",
    "\n",
    "out_path = './data/train.csv'\n",
    "\n",
    "create_csv(train_image_dir, train_annotation_dir, out_path, val_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the test data images are in the same root dir as training\n",
    "test_image_dir = data_dir + 'detectiondata/test/pos/'\n",
    "# but the annotations are downloaded separately and extracted into data_dir/evaluation/\n",
    "test_annotation_dir = data_dir + 'evaluation/annotations/'\n",
    "\n",
    "test_out_path = './data/test.csv'\n",
    "\n",
    "create_csv(test_image_dir, test_annotation_dir, test_out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Some visualization of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Hand Driver Bounding Boxes: 4949\n",
      "Right Hand Driver Bounding Boxes: 5354\n",
      "Left Hand Passenger Bounding Boxes: 1639\n",
      "Right Hand Passenger Bounding Boxes: 1287\n"
     ]
    }
   ],
   "source": [
    "train_annotations_paths = sorted(glob.glob(train_annotation_dir + '*'))\n",
    "\n",
    "#class names\n",
    "lh_d_label = 'leftHand_driver'\n",
    "rh_d_label = 'rightHand_driver'\n",
    "lh_p_label = 'leftHand_passenger'\n",
    "rh_p_label = 'rightHand_passenger'\n",
    "\n",
    "# each image can have up to 4 hand bboxes\n",
    "lh_d_count = 0\n",
    "rh_d_count = 0\n",
    "lh_p_count = 0\n",
    "rh_p_count = 0\n",
    "\n",
    "for annotations_path in train_annotations_paths:\n",
    "    anns = extract_box(annotations_path)\n",
    "    viewpoint = os.path.splitext(os.path.split(annotations_path)[1])[0].split('_')[-1]\n",
    "    for ann in anns:\n",
    "        if ann[0] == lh_d_label:\n",
    "            lh_d_count += 1\n",
    "        elif ann[0] == rh_d_label:\n",
    "            rh_d_count += 1\n",
    "        elif ann[0] == lh_p_label:\n",
    "            lh_p_count += 1\n",
    "        elif ann[0] == rh_p_label:\n",
    "            rh_p_count += 1\n",
    "\n",
    "print('Left Hand Driver Bounding Boxes: {}'.format(lh_d_count))\n",
    "print('Right Hand Driver Bounding Boxes: {}'.format(rh_d_count))\n",
    "print('Left Hand Passenger Bounding Boxes: {}'.format(lh_p_count))\n",
    "print('Right Hand Passenger Bounding Boxes: {}'.format(rh_p_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f761754a550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot\n",
    "plt.bar([0, 1, 2, 3], \n",
    "        [lh_d_count, rh_d_count, lh_p_count, rh_p_count], \n",
    "        tick_label=['Left Hand\\nDriver', 'Right Hand\\nDriver', 'Left Hand\\nPassenger', 'Right Hand\\nPassenger'])\n",
    "plt.savefig('./charts/classes_count.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge evaluates on two different levels:\n",
    "\n",
    "Level-1 (L1): hand instances with minimum height of 70 pixels, only over the shoulder (back) camera view.\n",
    "\n",
    "- Check height from annotation >= 70\n",
    "- From image name format `videoID_framenumber_vehicletype_driversubjectID_passengersubjectID_viewpoint.png` viewpoint is 3.\n",
    "\n",
    "Level-2 (L2): hand instances with minimum height of 25 pixels, all camera views.\n",
    "\n",
    "- Check height from annotation >= 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1: 6607\n",
      "L2: 12080\n"
     ]
    }
   ],
   "source": [
    "test_annotations_paths = sorted(glob.glob(test_annotation_dir + '*'))\n",
    "\n",
    "L1 = 0\n",
    "L2 = 0\n",
    "\n",
    "for annotations_path in test_annotations_paths:\n",
    "        anns = extract_box(annotations_path)\n",
    "        viewpoint = os.path.splitext(os.path.split(annotations_path)[1])[0].split('_')[-1]\n",
    "        for ann in anns:            \n",
    "            height = ann[2][1] - ann[1][1]\n",
    "            if viewpoint == '3' and height >= 70:\n",
    "                L1 += 1\n",
    "            \n",
    "            if height >= 25:\n",
    "                L2 += 1\n",
    "                \n",
    "\n",
    "print('L1: {}'.format(L1))\n",
    "print('L2: {}'.format(L2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
